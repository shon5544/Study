### 출처
* https://velog.io/@pu1etproof/%EB%82%98%EB%A7%8C%EC%9D%98-%EB%B0%B1%EA%B3%BC%EC%82%AC%EC%A0%84-%EB%A9%80%ED%8B%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81 (멀티 프로세싱)
* https://www.tutorialspoint.com/difference-between-asymmetric-and-symmetric-multiprocessing (멀티 프로세싱 대칭, 비대칭)
___
### 개요
* [[#FCFS]]
* [[#SJF(Shortest Job First)]]
* [[#SRTF]]
* [[#Round Robin]]
* [[#Time Quantum and Context Switch]]
* [[#MLFQ]]
* [[#Multi Processor Scheduling]]
* [[#Uniform & NUMA]]
___
### FCFS
<u><b>먼저온 프로세스가 먼저 CPU를 점유하는 방식이다. 비선점 방식으로 각 프로세스는 종료되거나 블락 상태가 되기 이전에 다른 프로세스에 의해 중단되지 않는다. </b></u> 가장 **간단한 방법으로 구현이 쉽고 단순**하다. 하지만 **Convoy Effect를 발생 시킬 수 있다는 단점**이 있다. 아래의 그림을 보자.

![[Pasted image 20231020164430.png]]
![[Pasted image 20231020164506.png]]

P2, P3는 실행시간이 짧음에도 불구하고 늦게 도착했기 때문에 오랜 대기를 수행해야만한다. 이와 같이 **수행시간이 긴 프로세스가 먼저 입력돼 다른 프로세스들이 긴 시간을 대기해야하는 현상을 Convoy Effect**라 한다. 이는 호위병 효과라는 의미인데 호위병이 먼저 지나가야 지나갈 수 있는 왕족의 모습을 긴 프로세스가 먼저 완료돼야 나머지 프로세스가 수행되는 현상에 빗댄 것이다.

호위병 효과가 발생했을 때 평균 응답시간을 측정해보면 $\frac{0+24+27}3 = 17$ 이지만 아래와 같이 순서를 변경하면 응답시간을 개선할 수 있다.

![[Pasted image 20231020164538.png]]

P1이 가장 마지막에 들어오는 경우 응답시간을 측정하면 $\frac{0+3+6}3 = 3$ 으로 엄청나게 개선된다.
* **Convoy Effect**
	호위병 효과가 발생하면 IO,CPU 모두 노는 최악의 상황이 발생할 수 있다. 긴 CPU 버스트를 가진 하나의 CPU 중심 프로세스와 짧은 CPU 버스트를 가진 많은 입출력 중심 프로세스가 순서대로 수행되고 있는 상황을 가정하자.
	
	CPU 처리시간이 긴 프로세스가 먼저 도착해 처리되면 그동안 IO는 계속 놀게 되고 이후 IO가 위주인 작업들이 들어오면 CPU가 계속해서 놀게된다. IO먼저 처리하면 훨씬 더 응답성을 개선 할 수 있었을 것이다.

___
### SJF(Shortest Job First)
짧은 작업을 우선시 하는 알고리즘으로 **수행시간이 짧은 작업부터 우선적으로 스케줄링**한다. <u><b>비선점 방식으로 각 프로세스는 작업 도중 자원을 강탈 당할 수 없다. 시스템에 도착하는 시간이 동일하다면 짧은 것 부터 실행한다.</b></u> 이 경우 동일한 시간에 작업이 도착한다면 성능을 개선할 수 있겠지만, <span class="red red-bg">수행시간이 짧은 프로세스가 늦게 들어오면 FCFS와 차이가 존재하지 않게 된다.</span>

* <span class="red red-bg">기아 문제</span>
	**SJF의 경우 작업시간이 짧은 프로세스만 우선적으로 실행하기 때문에 실행시간이 긴 프로세스의 경우 영영 실행되지 않을 가능성이 발생한다.**

> [!info]
> **SJF는 FIFO에 비해 나은 성능을 보여주지만, 프로세스의 실행시간을 정확히 예측할 수 없다는 어려움이 존재하기 때문에 실현에 어려움이 존재한다.**

![[Pasted image 20231020215116.png]]

___
### SRTF
<u><b>최소 잔여시간을 우선시 하는 방법으로 프로세스 간의 자원의 강탈이 가능한 선점 방식이다.</b></u> SRTF 평균 대기시간으로는 가장 짧은 방법이고 이것은 수학적으로 증명돼있다. 이런 점에서 보면 최적의 스케줄링 알고리즘 같지만 두가지 문제가 존재한다. 

첫번째로 **SRTF 그때 그때 연산을 진행해야 한다. 프로세스를 선택할 때 마다 잔존 수행시간이 가장 짧은 프로세스를 탐색**하고 이를 배치해야 한다. 

두번째로는 **기아 문제**가 존재한다. 만약 **수행시간이 긴 프로세스가 입력되고 이후에 계속해서 해당 프로세스보다 시간이 짧은 프로세스만 입력됐다고 생각해보자. 이 경우 긴 프로세스는 오랜 시간을 대기해도 영영 실행되지 않는 문제**가 발생할 수 있다.
![[Pasted image 20231018145703.png]]![[Pasted image 20231018145716.png]]
$Average\;Response\;Time=\frac{0+0+2+15}4 = 4.25$ 
응답 시간이나 대기 시간을 구할 때 도착시간을 고려해줘야 한다.
___
### Round Robin

<u><b>라운드 로빈은 모든 프로세스가 돌아가며 스케줄링 하는 것을 말한다. 이는 시분할 시스템에서 자주 사용하는 방식이며 현재의 OS에서도 이를 활용한다. </b></u>프로세스는 각각 일정 시간을 할당 받으며 특정 시간 수행한 이후에는 대기 상태로 돌아간다. 이러한 작업을 모든 프로세스가 완료 될 때까지 반복하는 방식이다. <span class="red red-bg">라운드 로빈은 선점 가능한 방식으로 각 프로세스는 시간이 지나면 자원을 뺏기고 대기 상태가 된다. </span>

**라운드 로빈의 핵심은 각 프로세스를 얼마간 실행할지를 결정하는 작업**이다. 이를 적절히 지정해야 프로세스의 대기시간과 CPU가 노는 시간을 줄일 수 있다. 너무 짧게 설정하면 각 프로세스가 차마 완수 되지 못하면서 로빈을 한 바퀴 더 돌게 돼 대기시간이 증대 될 수 있다. **너무 길 경우 FIFO와 차이가 없어진다.**

**라운드 로빈은 선점형으로 계속해서 프로세스의 교체가 발생하기 때문에 스위칭으로 인한 딜레이가 큰 편이다. 또한 무조건 주어진 시간만큼 실행되기 때문에 평균 응답 시간은 준수한 편이다.**

**라운드 로빈은 일관성을 갖고 동작해야 한다**. 예를 들어 특정 프로세스가 실행되는 와중 다른 프로세스가 도착했다 생각해보자. 이 경우 해당 프로세스를 로빈의 맨앞에 배치해 바로 실행할 지 로빈의 맨 끝에 배치해 마지막에 실행할지를 일관성을 갖고 수행해야한다. 즉 큐에 꼬리에 추가할지 머리에 추가할지는 일정해야 한다.
![[Pasted image 20231018153251.png]]
___
### Time Quantum and Context Switch
**라운드 로빈에의 할당 받는 사용 시간은 문맥교환에 소요되는 시간보다 더욱 많아야 한다.** 이 보다 작을 경우 문맥 교환에만 2번의 퀀텀이 요구되는 오버헤드가 발생할 수 있기 때문이다. 대부분의 현대 운영체제는 시간 퀀텀 값이 10-100 밀리세컨드 범위이고, 문맥 교환 시간은 10 마이크로세컨드 미만이다.
![[스크린샷 2023-10-18 오후 3.44.46.png]]
___
### MLFQ
MLFQ는 여러 개의 큐를 활용해 스케줄링을 구현하는 기법이다. 각 큐는 서로 다른 우선 순위를 가지며 스케줄러는 이를 고려해 실행할 프로세스를 추출한다. <span class="red red-bg">MLFQ는 프로세스가 아닌 큐에 고정적으로 우선순위를 부여하고 프로세스는 동적으로 각 큐를 이동하며 실행된다. </span> 이러한 방법을 활용해 aging 기법 등을 적용할 수도 있다. (큐에 머문 시간이 길어지면 우선순위가 높은 큐로 이동)

![[스크린샷 2023-10-18 오후 4.30.01.png]]

* **How it works?**
	* 첫 실행시 가장 높은 우선순위 큐에 편입된다.
	* CPU 사용시간을 전부 소모하면 우선 순위가 한 단계 낮아진다.
	* 주어진 시간을 소진하기전에 스위칭 당했을 경우 우선 순위를 유지한다.
	* 우선 순위가 낮을 수록 큐의 실행 시간은 길다.
	* <u><b>가장 우선순위가 낮은 큐는 Round Robin이 아닌 FCFS로 처리된다.</b></u>
	* <u><b>같은 큐 내부의 프로세스는 Round Robin으로 처리된다.</b></u>

#### Example
*  **긴 시간 동안 수행되는 프로세스 한 개가 존재하는 경우**
![[Pasted image 20231018162540.png]]

긴 프로세스 한개가 들어오는 경우 가장 맨 위 큐부터 시작해서 RR 방식으로 실행 되다가 우선 순위가 가장 낮은 큐까지 내려오는 것을 확인 할 수 있다. 확인해야 할점은 큐마다 할당되는 시간이 다르다는 점인데, **우선순위가 낮아질 수록 CPU를 차지할 수있는 시간이 길어진다는 것**을 확인 할 수 있다.

- **짧은 프로세스와 긴 프로세스가 같이 들어오는 경우**
![[Pasted image 20231018162640.png]]

프로세스 A는 프로세스 B가 들어오기 이전부터 실행돼 가장 우선순위가 낮은 큐에 위치한다. 이때100ms 쯤 프로세스 B가 도착하고 가장 우선순위가 높은 큐에 위치한다. 프로세스 A는 B에게 CPU를 양도하고 블락 상태가 된다. 이후 프로세스 B는 각 큐에서 RR방식으로 실행되다 종료된다. B가 종료되면 A만 남으므로 다시 작업을 재개한다.

이 부분에서 MLFQ의 핵심을 알 수 있다. **각 프로세스가 실질적으로 얼마나 수행 될지는 알 수 없지만 짧은 작업일 것이라 가정하고 높은 우선순위를 부여**한다. <span class="red red-bg">만약 정말 짧은 작업이면 높은 우선순위 큐에서 종료가 될 것이고 긴 작업이면 천천히 아래 큐로 이동하며 스스로 긴 작업임을 증명하게 된다. 이런 방식으로 SJF를 흉내낼 수 있다.</span> 이로 인해 IO 작업 등에 빠르게 반응해 응답성이 높은 편이다.

* **문제점**
	**MLFQ 역시 계속해서 신규 프로세스가 실행 되면서 위의 큐가 바쁠 경우 아래 큐에 놓인 프로세스들은 상대적으로 적게 할당 받는 기아 문제가 발생**할 수 있다. 이는 큐에 머문 시간이 특정 시간 이상이면 최상단의 큐로 프로세스를 이동 시키는 부스팅 기법이나 대기 시간이 길어질 수록 높은 큐로 단계적으로 이동하는 에이징 기법등을 통해 해결해 볼수 있다.
	
	또한 프로세스를 큐에서 큐로 이동 시키는 과정 등에서 오버헤드가 발생할 수 있다.
___
### Multi Processor Scheduling
이전까지 우리는 단일 코어 스케줄링에 대해 생각해 봤다. 단일 코어는 하나의 프로세서가 모든 작업을 처리해주기 때문에 스케줄러를 하나만 이용하면 되지만, <span class="red red-bg">여러 개의 프로세서를 활용하면 그 수 만큼의 스케줄러와 각 프로세서들을 조율하는 방법에 대해 생각해봐야 한다. </span>

우선적으로 고민해볼 것은 각 프로세서들의 동등 취급 여부이다. 비대칭은 각 프로세스에 차별을 두고 대칭은 차별을 두지 않는다.
#### 비대칭 멀티프로세싱(Asymmetric multiprocessing)
- master-slave 패턴을 사용하며 master 프로세서가 모든 os 작업을 처리한다.
- **각 프로세서들은 자신의 담당 프로세스만 수행한다.** 프로세서들은 통신할 일이 없고 각자 자신의 분야만 처리한다.
- **특정 작업만 몰렸을 때 해당 코어만 과부하 되는 상황이 발생할 수 있다.** (독립적이므로)
- **각 프로세서 들은 통신할 필요가 없기 때문에 공유자원이 존재하지 않는다**
- 설계가 단순하다.

#### 대칭 멀티프로세싱(Symmetric multiprocessing(SMP))
* 모든 프로세서가 OS 작업을 수행할 수 있다.
- **각 프로세서는 개별 스케줄러를 갖고 스케줄링을 진행한다.**
- 프로세스들은 하나의(공동의) 큐거나, 개별 큐에 저장되어 있다.
* **프로세서에서 공유 메모리를 통해 통신을 진행하며 동시 접근이 가능하기에 동기화 문제가 발생한다.
- 근래에는 다 이 방식을 사용한다.
- 하나의 프로세스를 다수 개의 프로세서가 병렬로 처리할 수 있다.
- <u><b>모든 프로세서가 동등하기 때문에 골고루 프로세스를 처리하도록 로드 밸런싱을 수행해줘야 한다. </b></u>
	- **Push migration**: 일감을 과부하 상태 CPU에서 다른 CPU로 옮기는 작업을 의미한다.
	* **Pull migration**: 여유있는 CPU에서 작업을 꺼내오는 것을 의미

![[스크린샷 2023-10-18 오후 8.21.33.png]]

![[스크린샷 2023-10-18 오후 5.49.34.png]]

> [!info]
> **비대칭일 경우 단일 스케줄러가 존재하고 스케줄링 된 유저 프로세스들을 Slave 프로세서가 처리한다.**

> [!info]
> **멀티 프로세서의 경우에도 각 프로세서 별로 IO,CPU burst가 적절히 배분되게 프로세스를 할당해야 한다.**

___
### Uniform & NUMA 
우리는 앞서 각 프로세서 별로 차별을 두는지 차별을 둔다면 어떻게 이용 하는지에 대해 확인을 했다. 이제 멀티 프로세서에서 메모리 영역을 어떻게 관리 하는지를 살펴보자.

* **Uniform**
	**유니폼은 프로세서가 메모리를 공유하는 형태를 말한다.** 전체 프로세서는 하나의 메모리를 자유롭게 공유하며 사용한다. 프로세스간 통신이 쉽다는 장점이 있지만, 프로세스가 많아지면 메모리 버스에 오버헤드가 발생하고 메모리 침범 등의 이슈가 발생할 수도 있다.

* **NUMA**
	**NUMA는 각 프로세서가 독립적인 지역 메모리를 사용하는 방식을 의미한다.** **각 프로세서는 각자의 로컬 메모리를 가지며 자신이 자주 사용하는 프로세스의 정보들을 해당 공간에 업로드한다.** NUMA를 사용하면 프로세스가 많을 경우 병목 현상을 방지하고 병렬 접근 성능을 향상 시킬 수 있다. 하지만 로컬 메모리를 생성하거나 접근 하는 등의 복잡한 처리를 진행해야 한다. 

![[스크린샷 2023-10-18 오후 8.21.07.png]]

* **Affinity**
	<u><b>프로세스의 친화도를 의미하며 프로세스가 프로세서를 이주할 때 드는 비용의 정도를 의미한다.</b></u> 다중 프로세서 환경에서는 특정 프로세서에서 실행되던 프로세스가 다른 프로세서로 스케줄링 될 가능성이 존재한다.
	
	NUMA 시스템을 활용 중이라면 이주는 오버헤드가 큰 작업이 되는데 이는 레지스터에 있던 값과 로컬 메모리에 위치한 값들을 옮겨줘야 하기 때문이다. 이러한 경우 친화도를 높다 표현하고 이주가 정말 어려운 경우 운영체제에서 강제로 이주를 불가능하게 설정하기도 있다.
___
