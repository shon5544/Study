### 출처
* https://ko.wikipedia.org/wiki/%EA%B0%80%EC%83%81_%EB%A9%94%EB%AA%A8%EB%A6%AC (가상 메모리)
* https://goodmilktea.tistory.com/36#google_vignette (요구 페이징 이미지)
* https://www.geeksforgeeks.org/operating-system-allocating-kernel-memory-buddy-system-slab-system/ (커널 메모리 할당)
___
### 개요
* [[#가상 메모리란]]
* [[#가상 주소 공간]]
* [[#요구 페이징]]
* [[#스와핑]]
* [[#페이지 폴트]]
* [[#페이지 교체란]]
* [[#페이지 교체 알고리즘]]
* [[#페이지 버퍼링 알고리즘]]
* [[#프로세스 프레임 할당]]
* [[#Thrashing]]
* [[#Kernel Memory Allocation]]
___
### 가상 메모리란
<span class="red red-bg"><b>가상 메모리는 가상의 논리 주소로 메모리에 접근해 각 개별 프로세스가 메모리의 전체 공간을 차지할 수 있다고 믿게 만드는 방식을 말한다.</b></span> 

가상 주소 공간의 크기는 명령어의 크기에 영향을 받으며, 이는 실제 메모리의 크기와는 관련이 없다. 예를 들어 32-bit 명령어 체계의 os라면 4GB의 가상 주소 공간을 가지게 된다. **가상 주소를 사용하면 각 프로세스 별로 큰 메모리 공간을 가지게 되므로 주소 공간이 부족해 프로세스를 실행하지 못하는 일은 발생하지 않게 된다.** 하지만 이는 가상의 공간에서의 가정이지 **실제 메모리는 하나이기 때문에 모든 프로세스가 실제로 렘을 독차지 하는 방식으로 동작할 수는 없다.**

<b><u>이에 따라 추가적으로 요구 페이징과 같은 기법들을 도입해 프로세스의 필요 페이지만을 부분 할당해 메모리의 가용성을 높인다.</u></b> 이를 활용하면 프로세스는 자신의 전체 데이터가 렘에 로딩됐다 생각하지만, 실제로는 사용하는 부분만 로딩된다. 이를 적절히 활용하면 **필요 페이지들만 실제 메모리에 부분적으로 로딩해 다중 프로그래밍에 효율적인 구조를 가질 수 있다.** 이외 사용하지 않는 부분은 디스크에 저장해 둔다. (스와핑)

**가상 주소 공간에서는 메모리 연속할당도 가능하다.** 실제 메모리는 외부 단편화로 인해 연속 할당이 어렵지만 논리 주소는 가상의 주소이기 때문에 실제 주소로 변환만 해준다면 논리 주소에선 메모리가 연속적으로 할당 됐다고 느끼게 할 수 있다. (MMU의 relocation register 값을 활용해 수행한다) **이로 인해 프로세스 단에서는 메모리에 복잡하게 접근 할 것 없이 연속적으로 접근해 할당하거나 해제하는 작업이 쉽게 가능하다.** (배열의 메모리 주소가 순차적으로 증가할 수 있는 까닭)
![[Pasted image 20231205145604.png]]
<span class="red red-bg">가상 메모리를 사용하면 프로세스간 메모리 주소 공간을 격리할 수도 있다. 또한 각 프로세스가 개별 가상주소로만 접근을 하기 때문에 실제 메모리에서의 충돌과 오염을 방지할 수 있다. </span>

요약하면 가상 메모리란 프로세스가 자유롭게 사용할 수 있는 가상의 큰 메모리 공간을 주는 방식으로 이는 나중에 실제 메모리 영역으로 치환된다. 프로세스 별로 실제 메모리를 전체 활용할 수는 없기 때문에 각 프로세스 별 필요한 부분 만을 메모리에 업로드한다. 이로 인해 다중 프로세스 실행에 강점을 가지며 프로세스의 사용하지 않는 부분은 Disk에 위치한다.
___
### 가상 주소 공간
가상 주소 공간은 가상 주소로 표현할 수 있는 가상의 메모리 공간을 말하며 실제 메모리의 크기가 아닌 word길이(32, 64bit)로 정해진다. <span class="red red-bg">프로세스가 참조하는 메모리 공간을 의미하며 각 프로세스 별 개별 가상 주소 공간을 갖는다. 프로세스의 관점에서 바라보는 메모리 공간 정도로 이해하면 된다.</span> 가상 주소 공간은 파격적인 구조로 생겼는데 그 형태는 아래와 같다.
![[Pasted image 20231205152643.png]]

**가상 주소 공간의 형태는 [[프로세스#Process Memory|프로세스 메모리]]에서 살펴본 메모리의 형태랑 동일하다. 앞서 말했듯 프로세스 관점에서 바라본 메모리 공간이 가상 주소 공간이기 때문이다**. 따라서 텍스트 ,코드, 데이터, 스텍, 힙 등으로 구분되는 메모리 구조를 사용하고 싶다면 논리주소를 사용해야만 한다.

> [!info]
> **가상 주소 공간은 프로세스의 관점에서 보는 메모리 공간으로 프로세스 메모리 구조를 쓰려면 가상주소를 활용해야만 한다.**

이미지를 보면 중간에 흰 부분이 존재하는 것을 확인할 수 있는데, 이는 프로세스에서 사용하지 않는 공간으로 sparse한 영역이라 부른다. 이러한 영역은 메모리가 런타임에서 헤제 되는 상황이 발생할때 생성된다.

* **가상 주소 공간의 크기  VS 가상 메모리의 크기**
가상 주소 공간의 크기는 명령어의 길이로 정해지므로 32-bit일 경우 4GB가 된다. **가상 메모리의 크기는 일반적으로 하드 디스크로 스왑된 메모리 자원들을 저장하는 스왑영역의 크기**를 말한다. (사실 이는 잘못된 표현이다. 이는 스왑 공간의 크기이지 가상 메모리의 크기가 아니기 때문이다. 하지만 윈도우는 그렇게 표시한다..)

가상 주소공간은 fork()를 사용했을 때 페이지를 곧장 복사하지 않고 우선 공유하다 변경시 복사하는 방식으로 동작한다. [[프로세스#Copy On Write|Copy On Write]]를 참조하자. 페이지를 완전 공유하는 얉은 복사를 원한다면 vfork()를 활용하면 된다.
___
### 요구 페이징
**요구 페이징은 프로세스에서 필요한 페이지만을 메모리에 로딩하는 방식**을 의미한다. 전체 페이지를 올리지 않기 때문에 효율적이고 그때 그때 적은 량의 IO만 수행하면 된다는 장점이 존재한다.

메모리는 제한적인 자원이기 때문에 페이지를 무한정 로딩할 수 없고 이에 따라 **로딩된 페이지를 메모리에서 내쫓아야하는 상황이 발생한다. 이때 페이지 단위의 swaping이 발생하는데 이를 진행하는 방식에 따라 성능 차이가 크게 발생**한다.
![[Pasted image 20231205161425.png]]

교체 할 페이지를 구분하기 위해 요구 페이징은 Valid bit를 활용한다. 이는 페이지 테이블 엔트리에 존재하는 비트로 해당 페이지의 메모리 로딩 여부를 표시한다. 해당 비트가 자세할 수록 더 다양한 상태를 기록할 수 있지만, 엔트리 크기가 커지면서 테이블의 크기가 비대 해질 수 있다.
___
### 스와핑

<span class="red red-bg">스와핑은 메모리의 용량이 가득차게 될 경우 기존의 페이지를 메모리가 아닌 Disc에 위치한 스왑 공간으로 쫓아내는 행위를 말한다. 이때 쫓겨나는 행위를 Swap-Out 들어오는 행위를 Swap-In이라고 한다. </span> **스왑 공간에 위치한 페이지는 Disk에 위치한 페이지를 탐색하는 것보단 빠르지만** 메모리에 비해 IO 시간이 배로 소모된다.
___
### 페이지 폴트
<u><b>페이지 폴트는 접근하고자 하는 페이지가 메모리에 로딩 돼 있지 않은 상황에서 발생한다. </b></u>페이지 폴트가 발생할 경우 스와핑이 발생 하고 이로 인해 일반적인 페이지 접근에 비해 시간이 오래 소요 된다. 만약 **페이지가 스왑 영역에 없거나 메모리에 더 이상 여유가 없어 페이지 교체 시간까지 요구 된다면 발생하는 오버헤드는 더욱 커진다.**

![[스크린샷 2023-12-05 오후 8.14.50.png]]

페이지 폴트의 발생순서는 다음과 같다. 
1. 페이지 테이블에서 접근할 페이지의 유효 비트를 확인한다.
2. 유효하지 않으므로 소프트웨어 인터럽트를 발생 시킨다.
3. 해당 페이지를 Disk 공간에서 탐색한다.
4. 탐색한 페이지를 메모리에 로딩한다. (교체 알고리즘도 이때 동작한다.)
5. 페이지 테이블의 비트를 수정한다.
6. 인터럽트 발생 이전 지점으로 돌아가 마저 실행한다.

* **페이지 폴트의 치명성**
디스크의 IO 속도는 메모리에 비해 수백배 이상 느리다. 이에 따라 낮은 빈도로 발생하는 페이지 폴트도 평균 메모리 접근 시간을 극단적으로 높일 수 있다. 따라서 최대한 폴트가 덜 발생하도록 페이지를 사용하는 것이 중요하다.

* **페이지 폴트를 줄이는 법**
<u><b>가장 좋은 방법은 메모리 크기를 늘리는 것이다.</b></u> 하지만 비용적으로 불가능한 경우가 많다. 따라서 한정된 메모리를 갖고 최대한의 효율을 뽑아내야 하는데 지역성 등을 활용해 페이지 히트 횟수를 늘리는 방법을 활용한다. (썼던 페이지 또 쓰기 등..)
___
### 페이지 교체란

메모리의 양이 제한적인 만큼 사용하지 않는 운영체제는 메모리를 비워내고 신규로 사용할 자원을 메모리로 들여오는 스와핑을 실행한다. <b><u>이떄 스와핑의 단위가 페이지 단위로 발생해 페이지가 교체되는 것을 페이지 교체라고 한다.</u></b> 페이지 교체는 페이지 교체 알고리즘을 활용해 진행되며 페이지를 신중하게 교체하기 위해 현재 페이지의 상태를 나타내는 dirty-bit를 활용하기도 한다. **만약 dirty-bit가 1인 페이지가 교체될 경우 디스크에 데이터를 반영한 후 교체된다.**

* **dirty bit(modify bit)**
**디스크 접근 시간은 상당 하므로 os는 페이지 데이터에 수정이 발생해도 이를 곧장 디스크에 반영하지 않고 메모리에만 반영해 가지고 있는다.**  따라서 전원이 나간다거나 메모리에 문제가 생길 경우 해당 데이터가 모조리 증발하는 문제를 갖고 있는데 이를 막고자 **OS는 여유가 발생할 때마다 페이지의 수정된 데이터를 디스크에도 반영을 해준다. 이때 값에 수정이 발생한 페이지를 특정해야 하는데 이를 위해 사용하는 것이 dirty-bit이다.** 

> [!info]
> **페이지 교체 알고리즘은 한정적인 메모리 자원에서 어떤 페이지를 쫓아낼지 결정하는 알고리즘이다.**

![[스크린샷 2023-12-05 오후 11.48.03.png]]
___
### 페이지 교체 알고리즘
페이지 교체 알고리즘은 페이지 교체 시 사용하는 알고리즘을 말하며 페이지 폴트 수를 최소로 하는 것을 목표로 한다.

#### FIFO
![[스크린샷 2023-12-05 오후 11.59.13.png]]

FIFO는 선입 선출의 방식을 활용해 페이지 교체를 진행하는 방식이다. 구현 난이도는 가장 쉽지만, 지역성을 고려하지 않기 때문에 페이지 폴트 비율은 알고리즘들 중 높은 편이다. 

* **Belady의 모순**
메모리의 크기가 더 증가했음에도 페이지 폴트의 수가 더 증가하는 현상을 말한다. 이러한 현상이 발생하는 이유는 메모리가 클 수록 페이지의 미래 사용성을 추측하기 어렵기 때문이다. belady의 역설은 FIFO와 같은 경우에서만 발생한다.

#### Optimal
최적 페이지 교체 방식은 가장 이상적인 페이지 교체 방식으로 **향후 가장 사용되지 않을 페이지를 교체하는 방식이다. 이론적으론 가장 적은 페이지 폴트를 발생 시키지만, 앞으로 사용될 페이지를 특정할 수 없기 때문에 이상적으로만 존재하는 알고리즘이다.**

![[스크린샷 2023-12-06 오전 12.12.26.png]]

#### LRU
LRU는 가장 오랫동안 사용하지 않은 페이지를 교체하는 방식이다. 준수한 폴트 비율을 보여주지만, **페이지들의 교체 기록을 관리해야하고 교체나 참조가 발생할 때 마다 히스토리에 해당 정보를 반영하는 오버헤드가 발생**한다.
![[스크린샷 2023-12-06 오전 12.15.34.png]]

#### LRU 유사 알고리즘(세컨드 찬스)
**세컨드 찬스 알고리즘은 페이지에게 두번의 기회를 주는 알고리즘으로 만약 최근에 활용했던 페이지일 경우 곧장 교체를 하지 않고 한번 더 기회를 준다**. 이때 페이지의 최근 참조 여부를 참조 비트를 활용해서 관리한다.
이를 활용할 경우 최근에 사용한 페이지가 곧장 교체되지 않기 때문에 지역성을 활용해 페이지 폴트 수를 줄일 수 있다.

* **참조 비트**
**참조 비트를 활용해 페이지가 참조 됐을 경우에는 1, 참조 되지 않았을 경우에는 0으로 설정한다. 이후 페이지들을 순회하며 페이지의 참조 값이 0인 페이지를 마주치면 교체한다.** 참조 비트를 2비트 사용하면 단순 참조 뿐 아니라 read,write 구분을 해 더 효율적인 교체를 진행할 수도 있다. 

예를 들어 비트 2개가 다 1일 경우 읽기와 쓰기가 모두 근래 진행된 페이지이고 1비트만 1일 경우 읽기 또는 쓰기만 진행된 페이지이다. 이에 따라 단순 참조 여부 뿐 아니라 다양한 속성을 활용해 효율적 교체가 가능하다.
![[스크린샷 2023-12-06 오전 12.34.37.png]]
___
### 페이지 버퍼링 알고리즘

<span class="red red-bg">페이지 버퍼링 알고리즘은 페이지를 우선적으로 읽어들이고 디스크에 나중에 반영하는 방식을 말한다. </span>페이지 버퍼링은 수정한 페이지에서 교체가 발생할 경우 페이지 교체와 동시에 디스크에 수정 내역을 반영하는 것이 아니라 우선적으로는 교체할 페이지를 프레임에 넣고 교체된 페이지의 데이터는 버퍼링 후 추후에 반영한다.
이후 디스크가 쉴때 마다 수정 내역을 디스크에 반영해준다. (여러 개를 모아서 한번에 처리한다)

이러한 방법을 사용하면 페이지 교체 때마다 디스크 IO가 발생하는 오버헤드를 제거할 수 있다. 이는 마치 메시지 큐와 흡사한 방법이라 볼수도 있다.
___
### 프로세스 프레임 할당

<b><u>프로세스에게 몇개의 프레임을 할당할 것인지 프레임을 어디서 가져와 교체 할 것인지 또한 고려해볼 문제이다. </u></b>프로세스에 적은 수의 프레임을 할당하면 페이지 폴트가 많이 발생해 오버헤드가 커질 수 있고 많은 수를 할당하면 메모리 낭비가 발생할 수 있다.

프레임을 어떻게 가져올지에 따라서도 차이가 발생한다. **만약 다른 프로세스의 프레임을 가져올 수 있다면 프레임을 비교적 자유롭게 할당 받을 수 있겠지만, [[스케쥴링 기법#Uniform & NUMA|NUMA]]를 활용하고 있을 경우 큰 오버헤드를 야기**할 수 있다. **이런식으로 사용할 프레임을 전체 메모리 공간에서 교체해 주는 것을 Global replacemnet라고 한다.**

**이와 반대로 프로세스에게 활용 가능한 프레임을 미리 할당하고 해당 프레임 내부에서만 교체를 계속해서 진행해 돌려쓰는 Local replacement도 존재**한다. 이는 Global에 비해 더욱 안정성 있고 NUMA에 더 적합하지만, 프로세스가 적은 양의 메모리를 사용할 경우 남는 프레임이 발생할 수 있다.
___
### Thrashing

**프로세스에 할당된 프레임의 수가 적어 페이지 교체 작업을 하는데 소모되는 오버헤드가 큰 상황**을 말한다. 이 경우 프로세스에 CPU의 사용률이 급감하며 프로그램의 성능저하가 발생한다.

쓰레싱이 발생하는 이유는 지나치게 많은 프로세스를 병행 실행했기 때문이다. <span class="red red-bg">프로세스의 수를 늘리면 어느 시점까지는 CPU의 사용률이 계속해서 증가하지만, 수가 지나치면 프로세스마다 적은 프레임을 할당 받으면서 페이지 폴트 비율이 증가하게 되고 이에 따라 CPU 사용률이 급감</span>하게 된다.

* **Working-Set**
**워킹 셋은 현재 자주 사용하는 페이지의 모음**으로 이를 모두 메모리에 상주 시킬 경우 폴트 비율을 낮출 수 있다. **워킹셋은 시간이 흐름에 따라 계속 변화하는데 이에 따라 워킹셋 윈도우 사이즈를 수정해 지역성을 띄는 페이지들이 메모리에 상주할 것을 보장한다. 이를 활용할 경우 페이지 지역성을 활용할 수 있어 쓰레싱을 방지할 수 있다** 

* **Page-Fault-Frequency**
페이지 폴트 빈도율을 활용한 메모리 관리는 페이지 폴트 비율을 활용해 페이지 폴트 비율이 정해진 상수 비율 이상으로 올라갈 경우 프레임을 추가 할당하고 내려갔을 경우 프레임을 반납하는 메모리 관리 방식이다.

![[스크린샷 2023-12-06 오후 1.52.05.png]]
___
### Kernel Memory Allocation

커널 또한 프로세스이고 메모리 할당을 받아야한다. **커널은 사용자와 달리 별도의 메모리 풀을 사용하고 페이징이 아닌 다른 방식을 사용해 메모리를 할당 받는다.** 이는 **커널 프로세스에서 활용하는 커널 자료구조가 페이지를 활용하기엔 작은 경우가 대다수이기 때문**이다. 커널 구조로 활용되는 것은  세마포어, 쓰레드, 파일 디스크립터 등인데 이를 표현하기 위해선 연속적으로 할당을 진행할 필요 등이 존재했고 이에 따라 별도의 메모리 할당을 하게 됐다. (커널 코드는 페이징 없이 연속할당 된다)

* **버디 시스템**
**커널 프로세스에 메모리를 할당하는 방법 중 하나로 2의 제곱승 단위로 고정 크기 메모리를 할당하는 방법이다.** 커널은 사용 가능한 프레임중 가장 큰 연속 프레임을 연속적으로 찾는다. 이후 **커널이 요구한 메모리 크기에 알맞도록 계속해서 반을 나누다 요구량 보다 큰 가장 가까운 수가 되면 이를 할당** 해준다. **이는 속도가 무척 빠르고 메모리도 연속 되므로 메모리의 합병도 간편하다. 하지만 내부 단편화가 발생할 수 있다는 단점도 존재**한다.

![[스크린샷 2023-12-06 오후 2.16.06.png]]

* **슬랩 시스템**
슬렙 시스템은 버디 시스템을 사용했을 경우 발생하는 단편화 문제를 해결한 방법이다. 슬랩 시스템은 두가지 객체를 사용해 구현되는데 바로 슬랩과 캐시이다. **슬랩은 하나 또는 그 이상의 페이지로 구성된 구조로 연속 메모리 공간에 위치한다. 캐시는 프로세스에서 자주 사용하는 슬랩들을 모아 놓는 공간으로 각 커널 자료 구조는 캐시를 할당 받는다.** 

슬렙은 다 차있거나, 비었거나, 부분적으로 차있을 수 있다. 여기서 차있다는 표현을 잘 구분해야하는데 차있다는 것은 슬랩 내부 페이지가 사용중인 것을 의미하고 비어있다는 페이지가 전부 사용중이 않다는 것을 의미한다. 

신규 커널 객체가 생성될 경우 해당 객체에 대한 정보를 부분적으로 차있는 슬랩에 할당한다. 부분적으로 차있는 슬랩이 없을 경우 빈 슬랩에 이를 할당하고 만약 빈 슬랩 마저 없을 경우 메모리 공간에 신규 슬랩을 생성한 후 캐시에 추가한다.

<b><u>슬랩 시스템은 각 커널 자료구조마다 자신에게 필요한 양만큼의 캐시를 전달 받기 때문에 메모리에 낭비가 발생하지 않는다. 또한 자신이 사용하는 메모리 영역의 위치를 캐시에 모아놓기 때문에 접근이 더 빠르다는 장점이 있다. </u></b> 또한 캐시를 삭제함으로써 할당 해제가 가능하기 때문에 메모리 헤제도 빠른 편이다. 

![[스크린샷 2023-12-06 오후 3.59.45.png]]
